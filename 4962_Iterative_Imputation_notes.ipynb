{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Codes for Imperative Imputation Notes\n",
    "\n",
    "# Note that the cell outputs and file links have been erased, and the notebook kernel has been reset to protect confidential data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "cv19_cat_df = pd.read_csv()\n",
    "\n",
    "print ( 'Done processing!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "iter_imp_start_time = time.perf_counter()\n",
    "\n",
    "cv19_cat_df.fillna(np.nan)\n",
    "\n",
    "iterative_imputer_cat = IterativeImputer(estimator = RandomForestClassifier(), initial_strategy = 'most_frequent', max_iter = 30, random_state = 2)\n",
    "\n",
    "cv19_cat_iter_imp = iterative_imputer_cat.fit_transform( cv19_cat_df )\n",
    "\n",
    "iter_imp_end_time = time.perf_counter()\n",
    "\n",
    "print ( 'Done processing!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv19_cat_iter_imp_df = pd.DataFrame(cv19_cat_iter_imp, columns = cv19_cat_df.columns )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iter_imp_time_minutes = ( iter_imp_end_time - iter_imp_start_time )/ 60\n",
    "\n",
    "print ('Iterative Imputation using Random Forest Classifier Time: ', str(iter_imp_time_minutes), ' minutes')\n",
    "\n",
    "cv19_cat_iter_imp_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv19_cat_feature_cols = list(cv19_cat_iter_imp_df.columns)\n",
    "\n",
    "cv19_cat_feature_cols.remove('evol_Death')\n",
    "\n",
    "cv19_cat_feature_cols.remove('evol_ICU_admission')\n",
    "\n",
    "cv19_cat_feature_cols.remove('evol_Hospitalization')\n",
    "\n",
    "cv19_cat_feature_cols.remove('evol_Recovered')\n",
    "\n",
    "cv19_cat_imp_features = cv19_cat_iter_imp_df[ cv19_cat_feature_cols ]\n",
    "\n",
    "\n",
    "cv19_cat_imp_deaths_labels = cv19_cat_iter_imp_df[ 'evol_Death']\n",
    "\n",
    "cv19_cat_imp_ICUs_labels = cv19_cat_iter_imp_df[ 'evol_ICU_admission']\n",
    "\n",
    "cv19_cat_imp_hospitalizations_labels = cv19_cat_iter_imp_df[ 'evol_Hospitalization']\n",
    "\n",
    "cv19_cat_imp_recovered_labels = cv19_cat_iter_imp_df[ 'evol_Recovered']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "start_train_test_split_metrics_time = time.perf_counter()\n",
    "\n",
    "cv19_deaths_features_training, cv19_deaths_features_testing, cv19_deaths_labels_training, cv19_deaths_labels_testing = train_test_split(cv19_cat_imp_features, cv19_cat_imp_deaths_labels, test_size = 0.2, random_state = 2)\n",
    "cv19_ICUs_features_training, cv19_ICUs_features_testing, cv19_ICUs_labels_training, cv19_ICUs_labels_testing = train_test_split(cv19_cat_imp_features, cv19_cat_imp_ICUs_labels, test_size = 0.2, random_state = 2)\n",
    "cv19_hospitalizations_features_training, cv19_hospitalizations_features_testing, cv19_hospitalizations_labels_training, cv19_hospitalizations_labels_testing = train_test_split(cv19_cat_imp_features, cv19_cat_imp_hospitalizations_labels, test_size = 0.2, random_state = 2)\n",
    "cv19_recovered_features_training, cv19_recovered_features_testing, cv19_recovered_labels_training, cv19_recovered_labels_testing = train_test_split(cv19_cat_imp_features, cv19_cat_imp_recovered_labels, test_size = 0.2, random_state = 2)\n",
    "\n",
    "\n",
    "deaths_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "deaths_lgr_clssr.fit ( cv19_deaths_features_training, cv19_deaths_labels_training )\n",
    "deaths_features_predictions = deaths_lgr_clssr.predict( cv19_deaths_features_testing )\n",
    "deaths_features_probabilities = deaths_lgr_clssr.predict_proba( cv19_deaths_features_testing )\n",
    "deaths_FPR, deaths_TPR, deaths_Thresholds = metrics.roc_curve( cv19_deaths_labels_testing, deaths_features_probabilities[:,1], pos_label = 1 )\n",
    "deaths_AUC = metrics.auc( deaths_FPR, deaths_TPR )\n",
    "deaths_features_accuracy = accuracy_score( cv19_deaths_labels_testing, deaths_features_predictions )\n",
    "\n",
    "\n",
    "ICUs_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "ICUs_lgr_clssr.fit ( cv19_ICUs_features_training, cv19_ICUs_labels_training )\n",
    "ICUs_features_predictions = ICUs_lgr_clssr.predict( cv19_ICUs_features_testing )\n",
    "ICUs_features_probabilities = ICUs_lgr_clssr.predict_proba( cv19_ICUs_features_testing )\n",
    "ICUs_FPR, ICUs_TPR, ICUs_Thresholds = metrics.roc_curve( cv19_ICUs_labels_testing , ICUs_features_probabilities[:,1], pos_label = 1 )\n",
    "ICUs_AUC = metrics.auc( ICUs_FPR, ICUs_TPR )\n",
    "ICUs_features_accuracy = accuracy_score( cv19_ICUs_labels_testing, ICUs_features_predictions )\n",
    "\n",
    "\n",
    "\n",
    "hospitalizations_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "hospitalizations_lgr_clssr.fit ( cv19_hospitalizations_features_training, cv19_hospitalizations_labels_training )\n",
    "hospitalizations_features_predictions = hospitalizations_lgr_clssr.predict( cv19_hospitalizations_features_testing )\n",
    "hospitalizations_features_probabilities = hospitalizations_lgr_clssr.predict_proba( cv19_hospitalizations_features_testing )\n",
    "HZs_FPR, HZs_TPR, HZs_Thresholds = metrics.roc_curve( cv19_hospitalizations_labels_testing , hospitalizations_features_probabilities[:,1], pos_label = 1 )\n",
    "HZs_AUC = metrics.auc( HZs_FPR, HZs_TPR )\n",
    "HZs_features_accuracy = accuracy_score( cv19_hospitalizations_labels_testing, hospitalizations_features_predictions )\n",
    "\n",
    " \n",
    "recovered_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "recovered_lgr_clssr.fit ( cv19_recovered_features_training, cv19_recovered_labels_training )\n",
    "recovered_features_predictions = recovered_lgr_clssr.predict( cv19_recovered_features_testing )\n",
    "recovered_features_probabilities = recovered_lgr_clssr.predict_proba( cv19_recovered_features_testing )\n",
    "RCV_FPR, RCV_TPR, RCV_Thresholds = metrics.roc_curve( cv19_recovered_labels_testing , recovered_features_probabilities[:,1], pos_label = 1 )\n",
    "RCV_AUC = metrics.auc( RCV_FPR, RCV_TPR )\n",
    "RCV_features_accuracy = accuracy_score( cv19_recovered_labels_testing, recovered_features_predictions )\n",
    "    \n",
    "    \n",
    "end_train_test_split_metrics_time = time.perf_counter()\n",
    "   \n",
    "print ( 'Done processing!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print ('Deaths Prediction Accuracy Score: ', str (deaths_features_accuracy ))\n",
    "print ('ICUs Prediction Accuracy Score: ', str (ICUs_features_accuracy ))\n",
    "print ('Hospitalization Prediction Accuracy Score: ', str (HZs_features_accuracy ))\n",
    "print ('Recovery Prediction Accuracy Score: ', str (RCV_features_accuracy ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "\n",
    "plt.plot( deaths_FPR, deaths_TPR, color='red', lw= 3, \n",
    "           label='Deaths Log Reg ROC Curve ( area = %0.4f)' % deaths_AUC )\n",
    "\n",
    "\n",
    "plt.plot( ICUs_FPR, ICUs_TPR, color='orange', lw= 3, \n",
    "           label='ICU Log Reg Trees ROC Curve ( area = %0.4f)' % ICUs_AUC )\n",
    "\n",
    "\n",
    "plt.plot( HZs_FPR, HZs_TPR, color='yellow', lw= 3, \n",
    "           label='Hospitalization Log Reg ROC Curve ( area = %0.4f)' % HZs_AUC )\n",
    "\n",
    "plt.plot( RCV_FPR, RCV_TPR, color='green', lw= 3, \n",
    "           label='Recovered Log Reg ROC Curve ( area = %0.4f)' % RCV_AUC )\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
