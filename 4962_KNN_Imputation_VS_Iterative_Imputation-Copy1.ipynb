{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Codes for comparing KNN and iterative imputation with RFC notes\n",
    "\n",
    "# Note that the cell outputs and file links have been erased, and the notebook kernel has been reset to protect confidential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# KNN VS Iterative w/ RFC Imputation Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# remember to check the file path names\n",
    "cv19_cat_df = pd.read_csv()\n",
    "\n",
    "#also remember to change the missing (null) values to numpy \"not a number\" or nan\n",
    "cv19_cat_df.fillna(np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# KNN Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# construct the knn imputator with 1 nearest neighbor\n",
    "knn1_imputer = KNNImputer(missing_values=np.nan, n_neighbors =1, weights='uniform', metric='nan_euclidean', copy ='False')\n",
    "\n",
    "# train (fit) the model, then transform does the imputation\n",
    "cv19_cat_knn_imp = knn1_imputer.fit_transform( cv19_cat_df )\n",
    "\n",
    "# this line creates a new dataframe with the data imputated\n",
    "cv19_cat_knn_imp_df = pd.DataFrame( cv19_cat_knn_imp, columns = cv19_cat_df.columns )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Iterative Imputation with Random Forest Classifier (RFC) <br> as the predicting algorithm <br> Note: Iterative Imputation may take a while\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# you can chose a different predicting algoirthm\n",
    "# 10 iterations should be decent - more iterations will take longer\n",
    "# you can also pick the random state number\n",
    "# construct the iterative imputer model with RFC as the classifier\n",
    "iterative_imputer = IterativeImputer(estimator = RandomForestClassifier(), initial_strategy = 'most_frequent', max_iter = 10, random_state = 2)\n",
    "\n",
    "# similar to the knn, you do training (fit) and then transform (imputing)\n",
    "cv19_cat_iter_imp = iterative_imputer.fit_transform(cv19_cat_df)\n",
    "\n",
    "# create the dataframe\n",
    "cv19_cat_iter_imp_df = pd.DataFrame(cv19_cat_iter_imp, columns = cv19_cat_df.columns)\n",
    "\n",
    "print('Done Processing!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setting up the dataframe sections (slices) for testing and training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the column names of the original data\n",
    "cv19_cat_feature_cols = list (cv19_cat_df.columns)\n",
    "\n",
    "# remove the names of the columns that are labels (also called targets, these are what we are tryingto predict)\n",
    "cv19_cat_feature_cols.remove('evol_Death')\n",
    "cv19_cat_feature_cols.remove('evol_ICU_admission')\n",
    "cv19_cat_feature_cols.remove('evol_Hospitalization')\n",
    "cv19_cat_feature_cols.remove('evol_Recovered')\n",
    "\n",
    "# create the feature section (also called feature matrix or X) for each dataframe\n",
    "cv19_cat_knn_features = cv19_cat_knn_imp_df[cv19_cat_feature_cols]\n",
    "cv19_cat_iter_features = cv19_cat_iter_imp_df[cv19_cat_feature_cols]\n",
    "\n",
    "#create the label sections (or simply Y)\n",
    "cv19_cat_knn_deaths_labels = cv19_cat_knn_imp_df[ 'evol_Death']\n",
    "cv19_cat_knn_ICUs_labels = cv19_cat_knn_imp_df[ 'evol_ICU_admission']\n",
    "cv19_cat_knn_hospitalizations_labels = cv19_cat_knn_imp_df[ 'evol_Hospitalization']\n",
    "cv19_cat_knn_recovered_labels = cv19_cat_knn_imp_df[ 'evol_Recovered']\n",
    "\n",
    "cv19_cat_iter_deaths_labels = cv19_cat_iter_imp_df[ 'evol_Death']\n",
    "cv19_cat_iter_ICUs_labels = cv19_cat_iter_imp_df[ 'evol_ICU_admission']\n",
    "cv19_cat_iter_hospitalizations_labels = cv19_cat_iter_imp_df[ 'evol_Hospitalization']\n",
    "cv19_cat_iter_recovered_labels = cv19_cat_iter_imp_df[ 'evol_Recovered']\n",
    "\n",
    "print('Done Processing!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Setting up the training sets and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Notes: you can name the sets whatevers\n",
    "# I choose to use obvious names to make things easier for myself\n",
    "\n",
    "# the format is\n",
    "# Features_Training, Features_Testing, Labels_Training, Labels_Testing = train_test_split(parameters)\n",
    "# the parameters follow the format ( Feature_Matrix, Labels_Matrix, test_size = #.##, random_state = ## )\n",
    "# test_size = 0.1 means 10% for testing and 90% for training, 0.2 means 20% for testing and 80% for training\n",
    "\n",
    "# setting up training and testing sets for knn imputated data\n",
    "knn_deaths_features_training, knn_deaths_features_testing, knn_deaths_labels_training, knn_deaths_labels_testing = train_test_split(cv19_cat_knn_features, cv19_cat_knn_deaths_labels, test_size = 0.2, random_state = 2)\n",
    "knn_ICUs_features_training, knn_ICUs_features_testing, knn_ICUs_labels_training, knn_ICUs_labels_testing = train_test_split(cv19_cat_knn_features, cv19_cat_knn_ICUs_labels, test_size = 0.2, random_state = 2)\n",
    "knn_hospitalizations_features_training, knn_hospitalizations_features_testing, knn_hospitalizations_labels_training, knn_hospitalizations_labels_testing = train_test_split(cv19_cat_knn_features, cv19_cat_knn_hospitalizations_labels, test_size = 0.2, random_state = 2)\n",
    "knn_recovered_features_training, knn_recovered_features_testing, knn_recovered_labels_training, knn_recovered_labels_testing = train_test_split(cv19_cat_knn_features, cv19_cat_knn_recovered_labels, test_size = 0.2, random_state = 2)\n",
    "\n",
    "#setting up training and testing sets for iterative w/ RFC imputated data\n",
    "iter_deaths_features_training, iter_deaths_features_testing, iter_deaths_labels_training, iter_deaths_labels_testing = train_test_split(cv19_cat_iter_features, cv19_cat_iter_deaths_labels, test_size = 0.2, random_state = 2)\n",
    "iter_ICUs_features_training, iter_ICUs_features_testing, iter_ICUs_labels_training, iter_ICUs_labels_testing = train_test_split(cv19_cat_iter_features, cv19_cat_iter_ICUs_labels, test_size = 0.2, random_state = 2)\n",
    "iter_hospitalizations_features_training, iter_hospitalizations_features_testing, iter_hospitalizations_labels_training, iter_hospitalizations_labels_testing = train_test_split(cv19_cat_iter_features, cv19_cat_iter_hospitalizations_labels, test_size = 0.2, random_state = 2)\n",
    "iter_recovered_features_training, iter_recovered_features_testing, iter_recovered_labels_training, iter_recovered_labels_testing = train_test_split(cv19_cat_iter_features, cv19_cat_iter_recovered_labels, test_size = 0.2, random_state = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training Logistic Regression Models\n",
    "\n",
    "Below codes will do deaths for knn and iterative imputated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# the order goes as follows:\n",
    "\n",
    "# construct the model - max_iter parameter can be omitted\n",
    "# model.fit (Features_Training, Labels_Training) - this trains the model\n",
    "# predictions = model.predict (Features_Testing) - this will use the model\n",
    "# to predict the labels of the testing features set\n",
    "# probabilities = model.predict_proba (Features_Testing)\n",
    "# algorithms like Logistic Regression can do this - some algorithms cannot do this\n",
    "# FPR, TPR, Thresholds = metrics.roc_curve ( Labels_Testing, probabilities[:, 1], pos_label = 1 )\n",
    "# AUC = metrics.auc (FPR, TPR)\n",
    "# accuracy = accuracy_score (Labels_Testing, predictions)\n",
    "\n",
    "# Note:\n",
    "# FPR, TPR, Thresholds = metrics.roc_curve ( Labels_Testing, probabilities[:,1], pos_label = 1 )\n",
    "# FPR is false positive rate, TPR is True positive rate, thresholds is the boundary that makes the decisions for each\n",
    "# normally in the probabilities list, it is a list of pairs. in this case the 2nd of the pair is the positive label\n",
    "# since \"1\" marks postive, you set that parameter\n",
    "# if the positive label is not a number, set pos_label = 'name value of positive'\n",
    "# if the positive label is the 1st of the pair, set probabilities[:,0]\n",
    "\n",
    "knn_deaths_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "knn_deaths_lgr_clssr.fit (knn_deaths_features_training, knn_deaths_labels_training)\n",
    "knn_deaths_features_predictions = knn_deaths_lgr_clssr.predict(knn_deaths_features_testing)\n",
    "knn_deaths_features_probabilities = knn_deaths_lgr_clssr.predict_proba(knn_deaths_features_testing)\n",
    "knn_deaths_FPR, knn_deaths_TPR, knn_deaths_Thresholds = metrics.roc_curve(knn_deaths_labels_testing, knn_deaths_features_probabilities[:,1], pos_label = 1)\n",
    "knn_deaths_AUC = metrics.auc(knn_deaths_FPR, knn_deaths_TPR)\n",
    "knn_deaths_features_accuracy = accuracy_score(knn_deaths_labels_testing, knn_deaths_features_predictions)\n",
    "\n",
    "\n",
    "iter_deaths_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "iter_deaths_lgr_clssr.fit (iter_deaths_features_training, iter_deaths_labels_training)\n",
    "iter_deaths_features_predictions = iter_deaths_lgr_clssr.predict(iter_deaths_features_testing)\n",
    "iter_deaths_features_probabilities = iter_deaths_lgr_clssr.predict_proba(iter_deaths_features_testing)\n",
    "iter_deaths_FPR, iter_deaths_TPR, iter_deaths_Thresholds = metrics.roc_curve(iter_deaths_labels_testing, iter_deaths_features_probabilities[:,1], pos_label = 1)\n",
    "iter_deaths_AUC = metrics.auc(iter_deaths_FPR, iter_deaths_TPR)\n",
    "iter_deaths_features_accuracy = accuracy_score(iter_deaths_labels_testing, iter_deaths_features_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print ('knn imputation deaths accuracy score: ', '%0.4f' % knn_deaths_features_accuracy ) \n",
    "print ('iterative imputation deaths accuracy score: ', '%0.4f' % iter_deaths_features_accuracy )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Using matplotlib to plot graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "\n",
    "# you need FPR, TPR, and AUC to plot graphs like below.\n",
    "\n",
    "plt.plot(knn_deaths_FPR, knn_deaths_TPR, color='red', lw= 3, \n",
    "           label='KNN Imputated Deaths ROC Curve ( area = %0.4f)' % knn_deaths_AUC)\n",
    "\n",
    "plt.plot(iter_deaths_FPR, iter_deaths_TPR, color='blue', lw= 3, \n",
    "           label='Iteratived Imputated Deaths ROC Curve ( area = %0.4f)' % iter_deaths_AUC)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=1, linestyle='--')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
