{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Codes on General Death Outcomes Notes<br>with A Focus on Chi Square vs. RFE\n",
    "# Note that the cell outputs and file links have been erased, and the notebook kernel has been reset to protect confidential data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# remember to check the file path names\n",
    "cv19_cat_df = pd.read_csv()\n",
    "\n",
    "#also remember to change the missing (null) values to numpy \"not a number\" or nan\n",
    "cv19_cat_df.fillna(np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# KNN Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# construct the knn imputator with 1 nearest neighbor\n",
    "knn1_imputer = KNNImputer(missing_values=np.nan, n_neighbors =1, weights='uniform', metric='nan_euclidean', copy ='False')\n",
    "\n",
    "# train (fit) the model, then transform does the imputation\n",
    "cv19_cat_knn_imp = knn1_imputer.fit_transform( cv19_cat_df )\n",
    "\n",
    "# this line creates a new dataframe with the data imputated\n",
    "cv19_cat_knn_imp_df = pd.DataFrame(cv19_cat_knn_imp, columns = cv19_cat_df.columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setting up the dataframe sections (slices) for testing and training the model, <br> and doing Chi Square Test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get the column names of the original data\n",
    "cv19_cat_feature_cols = list (cv19_cat_df.columns)\n",
    "\n",
    "# remove the names of the columns that are labels (also called targets, these are what we are tryingto predict)\n",
    "cv19_cat_feature_cols.remove('evol_Death')\n",
    "cv19_cat_feature_cols.remove('evol_ICU_admission')\n",
    "cv19_cat_feature_cols.remove('evol_Hospitalization')\n",
    "cv19_cat_feature_cols.remove('evol_Recovered')\n",
    "\n",
    "# create the feature section (also called feature matrix or X) for each dataframe\n",
    "cv19_cat_knn_features = cv19_cat_knn_imp_df[cv19_cat_feature_cols]\n",
    "\n",
    "#create the label sections (or simply Y)\n",
    "cv19_cat_knn_deaths_labels = cv19_cat_knn_imp_df[ 'evol_Death']\n",
    "\n",
    "\n",
    "# the features for chi square test\n",
    "cv19_cat_array = cv19_cat_knn_features.values\n",
    "\n",
    "# the death labels for chi square test\n",
    "cv19_cat_death_lb_array = cv19_cat_knn_deaths_labels.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Chi2 Square Test (For Death Outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the follow codes do feature selection\n",
    "# based on the goodness of fit tests using chi squared tests\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# setup the testing model for k = 10 features\n",
    "best10_chi2_deaths_label_test = SelectKBest(score_func=chi2, k= 10)\n",
    "\n",
    "# run/fit the testing model with the features and label(s)\n",
    "best10_chi2_deaths_label_test.fit(cv19_cat_array, cv19_cat_death_lb_array)\n",
    "\n",
    "# this is to get the indices of the column features that are kept by the model\n",
    "selected_chi2_deaths_features_indices_top10 = best10_chi2_deaths_label_test.get_support(indices = True)\n",
    "\n",
    "# this is to get the scores of the selected features\n",
    "selected_chi2_deaths_features_scores_top10 = best10_chi2_deaths_label_test.scores_[selected_chi2_deaths_features_indices_top10]\n",
    "\n",
    "# this is to get the feature names of the corresponding columns\n",
    "# in the dataframe\n",
    "selected_chi2_deaths_features_top10 = []\n",
    "for index in selected_chi2_deaths_features_indices_top10:\n",
    "    selected_chi2_deaths_features_top10.append(cv19_cat_knn_imp_df.columns[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the codes below generate a horizontal bar graph\n",
    "# for the top five features\n",
    "\n",
    "plt.rcdefaults()\n",
    "top10_chi2_figure, top10_chi2_axes = plt.subplots()\n",
    "top10_chi2_y_pos = np.arange( len(selected_chi2_deaths_features_top10) )\n",
    "top10_chi2_axes.barh( top10_chi2_y_pos, width = selected_chi2_deaths_features_scores_top10, color='red', align='center' )\n",
    "top10_chi2_axes.set_yticks( top10_chi2_y_pos )\n",
    "top10_chi2_axes.set_yticklabels(selected_chi2_deaths_features_top10)\n",
    "top10_chi2_axes.invert_yaxis()\n",
    "top10_chi2_axes.set_xlabel('Chi Squared Test Scores')\n",
    "top10_chi2_axes.set_title('Chi Squared Test Scores of The Top Ten\\nFeatures of Death Outcomes Using KNN Imputation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recursive Feature Elimination (RFE) w/ Random Forest Classifier (RFC)\n",
    "\n",
    "# Note: Although Support Vector Machines (SVM) Classifiers are recommended for this dataset, Random Forest is a good algorithm for a general dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setting up the RFE model for 5 features\n",
    "rfe_deaths_label_test = RFE(estimator = RandomForestClassifier(), n_features_to_select = 10, step = 1)\n",
    "\n",
    "# run/fit the testing model with the features and label(s)\n",
    "rfe_deaths_label_test.fit(cv19_cat_array, cv19_cat_death_lb_array)\n",
    "\n",
    "# this is to get the indices of the column features that are kept by the models\n",
    "selected_rfe_deaths_features_indices_top10 = rfe_deaths_label_test.get_support(indices = True)\n",
    "\n",
    "# this is to get the scores of the selected features\n",
    "selected_rfe_deaths_features_ranks = rfe_deaths_label_test.ranking_\n",
    "\n",
    "selected_top10_rfe_deaths_features = []\n",
    "for index in selected_top10_rfe_deaths_features_indices:\n",
    "    selected_top10_rfe_deaths_features.append(cv19_cat_knn_imp_df.columns[index])\n",
    "    \n",
    "print('Done Processing!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Note: Unlike Chi Squared Tests which selects features by test scores,<br> Recursive Feature Elimination assigns ranks to features,<br>with 1 being the highest. <br> Also note, because Random Forest is used for ranking, the results may change each iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfe_ranks_df = pd.DataFrame(selected_rfe_deaths_features_ranks, index = cv19_cat_knn_features.columns, columns= ['Feature Rank']).sort_values(by='Feature Rank', ascending = True)\n",
    "\n",
    "rfe_ranks_df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Recursive Feature Elimination w/ Cross Validation (RFECV)<br>Using the Random Forest Classifier (RFC)<br> Note: RFECV will pick k number of features at minimum, so it is possible to have more than k features selected by RFECV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# unlike RFE, this selects AT MINIMUM k number of chosen features\n",
    "# the setup is similar to RFE, except that the n_jobs parameter will determine the number of cpu cores\n",
    "# allocated to handle the cross validation folds.\n",
    "rfecv_for_deaths = RFECV(estimator = RandomForestClassifier(), step = 1, min_features_to_select = 8, cv = 10, n_jobs = -1)\n",
    "\n",
    "rfecv_for_deaths.fit(cv19_cat_array, cv19_cat_death_lb_array)\n",
    "\n",
    "rfecv_selected_top_deaths_features_indices = rfecv_for_deaths.get_support(indices = True)\n",
    "\n",
    "rfecv_deaths_features_grid_scores = rfecv_for_deaths.grid_scores_\n",
    "\n",
    "rfecv_deaths_features_rankings = rfecv_for_deaths.ranking_\n",
    "\n",
    "rfecv_selected_top_deaths_features = []\n",
    "for index in rfecv_selected_top_deaths_features_indices:\n",
    "    rfecv_selected_top_deaths_features.append(cv19_cat_knn_imp_df.columns[index])\n",
    "\n",
    "print('Done Processing!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfecv_ranks_df = pd.DataFrame(rfecv_deaths_features_rankings, index = cv19_cat_knn_features.columns,columns= ['Feature Rank']).sort_values(by='Feature Rank', ascending = True)\n",
    "\n",
    "rfecv_ranks_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dataframe section (slice) of the top 10 death outcome features<br>selected by Chi Squared Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chi2_10_features = cv19_cat_knn_imp_df[selected_chi2_deaths_features_top10]\n",
    "chi2_10_features.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dataframe section (slice) of the top 10 death outcome features<br>selected by Recursive Feature Elimination method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfe_10_features = cv19_cat_knn_imp_df[selected_top10_rfe_deaths_features]\n",
    "rfe_10_features.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Dataframe section (slice) of the top death outcome features<br>selected by Recursive Feature Elimination w/ Cross Validation method. <br>Note: more than 10 features may be selected, but these are just used to reference to the other two feature sets selected by the other two methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "refcv_10_features = cv19_cat_knn_imp_df[rfecv_selected_top_deaths_features]\n",
    "refcv_10_features.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setting up the Training and Testing Sets.<br> Note: 20% testing size, 80% training, random state = 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "chi2_10_deaths_features_training, chi2_10_deaths_features_testing, chi2_10_deaths_label_training, chi2_10_deaths_label_testing = train_test_split(chi2_10_features, cv19_cat_knn_deaths_labels, test_size = 0.2, random_state = 2)\n",
    "rfe_10_deaths_features_training, rfe_10_deaths_features_testing, rfe_10_deaths_label_training, rfe_10_deaths_label_testing = train_test_split(rfe_10_features, cv19_cat_knn_deaths_labels, test_size = 0.2, random_state = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Logistic Regression Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "chi2_deaths_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "chi2_deaths_lgr_clssr.fit (chi2_10_deaths_features_training, chi2_10_deaths_label_training)\n",
    "chi2_deaths_features_predictions = chi2_deaths_lgr_clssr.predict(chi2_10_deaths_features_testing)\n",
    "chi2_deaths_features_probabilities = chi2_deaths_lgr_clssr.predict_proba(chi2_10_deaths_features_testing)\n",
    "chi2_deaths_FPR, chi2_deaths_TPR, chi2_deaths_Thresholds = metrics.roc_curve(chi2_10_deaths_label_testing, chi2_deaths_features_probabilities[:,1], pos_label = 1)\n",
    "chi2_deaths_AUC = metrics.auc(chi2_deaths_FPR, chi2_deaths_TPR)\n",
    "chi2_deaths_features_accuracy = accuracy_score(chi2_10_deaths_label_testing, chi2_deaths_features_predictions)\n",
    "\n",
    "\n",
    "rfe_deaths_lgr_clssr = LogisticRegression(max_iter=1500)\n",
    "rfe_deaths_lgr_clssr.fit (rfe_10_deaths_features_training, rfe_10_deaths_label_training)\n",
    "rfe_deaths_features_predictions = rfe_deaths_lgr_clssr.predict(rfe_10_deaths_features_testing)\n",
    "rfe_deaths_features_probabilities = rfe_deaths_lgr_clssr.predict_proba(rfe_10_deaths_features_testing)\n",
    "rfe_deaths_FPR, rfe_deaths_TPR, rfe_deaths_Thresholds = metrics.roc_curve(rfe_10_deaths_label_testing, rfe_deaths_features_probabilities[:,1], pos_label = 1)\n",
    "rfe_deaths_AUC = metrics.auc(rfe_deaths_FPR, rfe_deaths_TPR)\n",
    "rfe_deaths_features_accuracy = accuracy_score(rfe_10_deaths_label_testing, rfe_deaths_features_predictions)\n",
    "\n",
    "\n",
    "print('Deaths Accuracy Score of Chi Square Features: ', '%0.4f' % rfe_deaths_features_accuracy, '.')\n",
    "print('Deaths Accuracy Score of RFE Features: ', '%0.4f' % rfe_deaths_features_accuracy, '.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "plt.figure(figsize =(12, 8))\n",
    "\n",
    "# you need FPR, TPR, and AUC to plot graphs like below.\n",
    "\n",
    "plt.plot(chi2_deaths_FPR, chi2_deaths_TPR, color='red', lw= 3, \n",
    "           label='Chi2 Top 10 Death Features ROC Curve ( area = %0.4f)' % chi2_deaths_AUC)\n",
    "\n",
    "plt.plot(rfe_deaths_FPR, rfe_deaths_TPR, color='orange', lw= 3, \n",
    "           label='RFE Top 10 ROC Curve ( area = %0.4f)' % rfe_deaths_AUC)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='blue', lw=2, \n",
    "         label ='Random Guess Line',linestyle='--')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
